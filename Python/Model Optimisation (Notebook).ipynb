{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Artificial Neural Network (ANN) Search and Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers the following:\n",
    "- Hyperparameter Tuning\n",
    "- Model Evaluation\n",
    "- RMSE Scores\n",
    "- Training History\n",
    "- Actual vs Predicted Scatter Plot\n",
    "\n",
    "At the end, this notebook presents 4 optimised models, saved to the current directory:\n",
    "- Pressure Model optimised with Hyperband\n",
    "- Pressure Model optimised with Bayesian Optimisation\n",
    "- Temperature Model optimised with Hyperband\n",
    "- Temperature Model optimised with Bayesian Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential # base model\n",
    "from keras.layers import Dense, Normalization, InputLayer # layers\n",
    "from keras.optimizers import SGD, RMSprop, Adam, AdamW, Adadelta, Adagrad, Adamax, Adafactor, Nadam, Ftrl # optimisers\n",
    "from keras_tuner import HyperModel, Hyperband, BayesianOptimization # for hyperparameter tuning\n",
    "from keras.callbacks import EarlyStopping, TerminateOnNaN # regularisation\n",
    "from sklearn.metrics import mean_squared_error # evaluation metrics\n",
    "\n",
    "# utility\n",
    "from keras.backend import clear_session\n",
    "from tensorflow_docs.modeling import EpochDots\n",
    "from keras.models import load_model\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp\n",
    "temp_X_train = pd.read_csv(\"data/temperature_train.csv\").values[:,:-1]\n",
    "temp_y_train = pd.read_csv(\"data/temperature_train.csv\").values[:,-1]\n",
    "temp_X_val = pd.read_csv(\"data/temperature_val.csv\").values[:,:-1]\n",
    "temp_y_val = pd.read_csv(\"data/temperature_val.csv\").values[:,-1]\n",
    "temp_X_test = pd.read_csv(\"data/temperature_test.csv\").values[:,:-1]\n",
    "temp_y_test = pd.read_csv(\"data/temperature_test.csv\").values[:,-1]\n",
    "temp_X_combined = pd.read_csv(\"data/temperature_combined.csv\").values[:,:-1]\n",
    "temp_y_combined = pd.read_csv(\"data/temperature_combined.csv\").values[:,-1]\n",
    "\n",
    "# pressure\n",
    "pressure_X_train = pd.read_csv(\"data/pressure_train.csv\").values[:,:-1]\n",
    "pressure_y_train = pd.read_csv(\"data/pressure_train.csv\").values[:,-1]\n",
    "pressure_X_val = pd.read_csv(\"data/pressure_val.csv\").values[:,:-1]\n",
    "pressure_y_val = pd.read_csv(\"data/pressure_val.csv\").values[:,-1]\n",
    "pressure_X_test = pd.read_csv(\"data/pressure_test.csv\").values[:,:-1]\n",
    "pressure_y_test = pd.read_csv(\"data/pressure_test.csv\").values[:,-1]\n",
    "pressure_X_combined = pd.read_csv(\"data/pressure_combined.csv\").values[:,:-1]\n",
    "pressure_y_combined = pd.read_csv(\"data/pressure_combined.csv\").values[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "This section retrieves a set of best N hyperparameters for the temperature and pressure model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_Int = (1, 100) # number of units in hidden layer\n",
    "hidden_Int = (1, 3) # number of hidden layers\n",
    "activation_Choice = ['relu', 'leaky_relu', 'elu', 'gelu', 'silu'] # activation function\n",
    "optimizer_Choice = ['sgd', 'rmsprop', 'adam'] # optimiser\n",
    "learning_rate_Log = (0.001, 0.1) # learning rate\n",
    "batch_size_Int = (16, 64) # batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildModelTemplate(X_train):\n",
    "\tclass ModelTemplate(HyperModel):\n",
    "\n",
    "\t\t# utility function to build optimiser with custom learning rate\n",
    "\t\tdef build_optimizer(self, hp):\n",
    "\t\t\toptimizer_string = hp.Choice('optimizer', values=optimizer_Choice)\n",
    "\t\t\tlearning_rate = hp.Float('learning_rate', *learning_rate_Log, sampling='log')\n",
    "\t\t\twith hp.conditional_scope('optimizer', ['adam']):\n",
    "\t\t\t\tif optimizer_string == 'adam': optimzer = Adam(learning_rate)\n",
    "\t\t\twith hp.conditional_scope('optimizer', ['adamw']):\n",
    "\t\t\t\tif optimizer_string == 'adamw': optimzer = AdamW(learning_rate)\n",
    "\t\t\twith hp.conditional_scope('optimizer', ['rmsprop']):\n",
    "\t\t\t\tif optimizer_string == 'rmsprop': optimzer = RMSprop(learning_rate)\n",
    "\t\t\twith hp.conditional_scope('optimizer', ['sgd']):\n",
    "\t\t\t\tif optimizer_string == 'sgd': optimzer = SGD(learning_rate)\n",
    "\t\t\twith hp.conditional_scope('optimizer', ['adadelta']):\n",
    "\t\t\t\tif optimizer_string == 'adadelta': optimzer = Adadelta(learning_rate)\n",
    "\t\t\twith hp.conditional_scope('optimizer', ['adagrad']):\n",
    "\t\t\t\tif optimizer_string == 'adagrad': optimzer = Adagrad(learning_rate)\n",
    "\t\t\twith hp.conditional_scope('optimizer', ['adamax']):\n",
    "\t\t\t\tif optimizer_string == 'adamax': optimzer = Adamax(learning_rate)\n",
    "\t\t\twith hp.conditional_scope('optimizer', ['adafactor']):\n",
    "\t\t\t\tif optimizer_string == 'adafactor': optimzer = Adafactor(learning_rate)\n",
    "\t\t\twith hp.conditional_scope('optimizer', ['nadam']):\n",
    "\t\t\t\tif optimizer_string == 'nadam': optimzer = Nadam(learning_rate)\n",
    "\t\t\twith hp.conditional_scope('optimizer', ['ftrl']):\n",
    "\t\t\t\tif optimizer_string == 'ftrl': optimzer = Ftrl(learning_rate)\n",
    "\t\t\treturn optimzer\n",
    "\n",
    "\t\t# model structure\n",
    "\t\tdef build(self, hp):\n",
    "\t\t\tmodel = Sequential() # base\n",
    "\t\t\tmodel.add(InputLayer((6,))) # input\n",
    "\n",
    "\t\t\t# z-score normalisation\n",
    "\t\t\tNormLayer = Normalization() \n",
    "\t\t\tNormLayer.adapt(X_train)\n",
    "\t\t\tmodel.add(NormLayer)\n",
    "\n",
    "\t\t\t# hidden layers\n",
    "\t\t\tfor i in range(hp.Int('hidden', *hidden_Int)):\n",
    "\t\t\t\twith hp.conditional_scope('hidden', list(range(i+1, hidden_Int[1]+1))):\n",
    "\t\t\t\t\tmodel.add(Dense(\n",
    "\t\t\t\t\t\tunits = hp.Int(f'units{i}', *units_Int), # units\n",
    "\t\t\t\t\t\tactivation = hp.Choice(f'activation{i}', activation_Choice), # activation\n",
    "\t\t\t\t\t))\n",
    "\t\t\t\n",
    "\t\t\tmodel.add(Dense(1)) # output\n",
    "\t\t\tmodel.compile(\n",
    "\t\t\t\toptimizer = self.build_optimizer(hp), \n",
    "\t\t\t\tloss = 'mse' # mean squared error loss function\n",
    "\t\t\t)\n",
    "\t\t\treturn model\n",
    "\n",
    "\t\tdef fit(self, hp, model, *args, **kwargs):\n",
    "\t\t\tbatch_size = hp.Int('batch_size', *batch_size_Int)\n",
    "\t\t\treturn model.fit(batch_size = batch_size, *args, **kwargs)\n",
    "\t\t\n",
    "\treturn ModelTemplate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # for hyperband\n",
    "max_epochs = 1000\n",
    "factor = 3\n",
    "hyperband_iterations = 1\n",
    "\n",
    "# for bayesian optimisation\n",
    "max_trials = 2000\n",
    "\n",
    "directory = 'trials'\n",
    "\n",
    "def HyperbandSearch(X_train, y_train, X_val, y_val, project_name):\n",
    "\ttuner = Hyperband(\n",
    "\t\tBuildModelTemplate(X_train),\n",
    "\t\tobjective = 'val_loss',\n",
    "\t\tmax_epochs = max_epochs,\n",
    "\t\tfactor = factor,\n",
    "\t\thyperband_iterations = hyperband_iterations,\n",
    "\t\tdirectory = directory,\n",
    "\t\tproject_name = project_name,\n",
    "\t\tmax_consecutive_failed_trials = 10\n",
    "\t)\n",
    "\ttuner.search(\n",
    "\t\tx = X_train,\n",
    "\t\ty = y_train,\n",
    "\t\tvalidation_data = (X_val, y_val),\n",
    "\t\tverbose = 2,\n",
    "\t\tcallbacks = [EarlyStopping(monitor='val_loss', patience=10), TerminateOnNaN()]\n",
    "\t)\n",
    "\treturn tuner\n",
    "\n",
    "def BayesianOptimisationSearch(X_train, y_train, X_val, y_val, project_name):\n",
    "\ttuner = BayesianOptimization(\n",
    "\t\tBuildModelTemplate(X_train),\n",
    "\t\tobjective = 'val_loss',\n",
    "\t\tmax_trials = max_trials,\n",
    "\t\tdirectory = directory,\n",
    "\t\tproject_name = project_name,\n",
    "\t\tmax_consecutive_failed_trials = 10\n",
    "\t)\n",
    "\ttuner.search(\n",
    "\t\tx = X_train,\n",
    "\t\ty = y_train,\n",
    "\t\tvalidation_data = (X_val, y_val),\n",
    "\t\tepochs = 10,\n",
    "\t\tverbose = 2,\n",
    "\t\tcallbacks = [EarlyStopping(monitor='val_loss', patience=10), TerminateOnNaN()],\n",
    "\t)\n",
    "\treturn tuner\n",
    "\n",
    "# search pressure models - Hyperband\n",
    "pressure_tuner_hyperband = HyperbandSearch(pressure_X_train, pressure_y_train, pressure_X_val, pressure_y_val, 'pressure_hyperband')\n",
    "temp_tuner_hyperband = HyperbandSearch(temp_X_train, temp_y_train, temp_X_val, temp_y_val, 'temp_hyperband')\n",
    "pressure_tuner_bayesian = BayesianOptimisationSearch(pressure_X_train, pressure_y_train, pressure_X_val, pressure_y_val, 'pressure_bayesian')\n",
    "temp_tuner_bayesian = BayesianOptimisationSearch(temp_X_train, temp_y_train, temp_X_val, temp_y_val, 'temp_bayesian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best N Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "pressure_best_hps_hyperband = pressure_tuner_hyperband.get_best_hyperparameters(num_trials=N)\n",
    "pressure_best_hps_bayesian = pressure_tuner_hyperband.get_best_hyperparameters(num_trials=N)\n",
    "temp_best_hps_hyperband = temp_tuner_hyperband.get_best_hyperparameters(num_trials=N)\n",
    "temp_best_hps_bayesian = temp_tuner_bayesian.get_best_hyperparameters(num_trials=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "This section trains the models for 1000 epochs using the best N hyperparameters found above, and evaluates it against the train, validation, test and combined sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, y_train, X_val, y_val, tuner, hps):\n",
    "    models = []\n",
    "    for i, hp in enumerate(hps):\n",
    "        try:\n",
    "            clear_session()\n",
    "\n",
    "            # load hyperparameters\n",
    "            model = tuner.hypermodel.build(hp)\n",
    "            batch_size = hp.get_config()['values']['batch_size']\n",
    "            print(f'\\nTraining Model {i}:')\n",
    "            print(f'Batch Size: {batch_size}')\n",
    "\n",
    "            # fit model\n",
    "            model.fit(\n",
    "                x = X_train,\n",
    "                y = y_train,\n",
    "                validation_data = (X_val, y_val),\n",
    "                batch_size = batch_size,\n",
    "                epochs = 1000,\n",
    "                verbose = 0,\n",
    "                callbacks = [\n",
    "                    EpochDots(report_every=100), \n",
    "                    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "                ]\n",
    "            )\n",
    "            models.append(model)\n",
    "        except: pass\n",
    "    return models\n",
    "\n",
    "pressure_models_hyperband = train_models(pressure_X_train, pressure_y_train, pressure_X_val, pressure_y_val, pressure_tuner_hyperband, pressure_best_hps_hyperband)\n",
    "pressure_models_bayesian = train_models(pressure_X_train, pressure_y_train, pressure_X_val, pressure_y_val, pressure_tuner_bayesian, pressure_best_hps_bayesian)\n",
    "temp_models_hyperband = train_models(temp_X_train, temp_y_train, temp_X_val, temp_y_val, temp_tuner_hyperband, pressure_best_hps_hyperband)\n",
    "temp_models_bayesian = train_models(temp_X_train, temp_y_train, temp_X_val, temp_y_val, temp_tuner_bayesian, temp_best_hps_bayesian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RMSE Scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function for obtaining RMSE for train, validation, test and combined sets for a single model\n",
    "def evaluate_model(X_train, y_train, X_val, y_val, X_test, y_test, X_combined, y_combined, model):\n",
    "    rmse = lambda y, y_pred: mean_squared_error(y, y_pred, squared=False)\n",
    "    return [\n",
    "        rmse(y_train, model.predict(X_train)),\n",
    "        rmse(y_val, model.predict(X_val)),\n",
    "        rmse(y_test, model.predict(X_test)),\n",
    "        rmse(y_combined, model.predict(X_combined))\n",
    "    ]\n",
    "\n",
    "# utility function for obtaining RMSE for train, validation, test and combined sets for a list of models\n",
    "def evaluate_models(X_train, y_train, X_val, y_val, X_test, y_test, X_combined, y_combined, models):\n",
    "    results = []\n",
    "    for model in models:\n",
    "        try: results.append(evaluate_model(X_train, y_train, X_val, y_val, X_test, y_test, X_combined, y_combined, model))\n",
    "        except: pass\n",
    "    return pd.DataFrame(results, columns=['rmse_train', 'rmse_val', 'rmse_test', 'rmse_combined'])\n",
    "\n",
    "pressure_results_hyperband = evaluate_models(\n",
    "    pressure_X_train, pressure_y_train,\n",
    "    pressure_X_val, pressure_y_val,\n",
    "    pressure_X_test, pressure_y_test,\n",
    "    pressure_X_combined, pressure_y_combined,\n",
    "    pressure_models_hyperband\n",
    ")\n",
    "pressure_results_bayesian = evaluate_models(\n",
    "    pressure_X_train, pressure_y_train,\n",
    "    pressure_X_val, pressure_y_val,\n",
    "    pressure_X_test, pressure_y_test,\n",
    "    pressure_X_combined, pressure_y_combined,\n",
    "    pressure_models_bayesian\n",
    ")\n",
    "temp_results_hyperband = evaluate_models(\n",
    "    temp_X_train, temp_y_train,\n",
    "    temp_X_val, temp_y_val,\n",
    "    temp_X_test, temp_y_test,\n",
    "    temp_X_combined, temp_y_combined,\n",
    "    temp_models_hyperband\n",
    ")\n",
    "temp_results_bayesian = evaluate_models(\n",
    "    temp_X_train, temp_y_train,\n",
    "    temp_X_val, temp_y_val,\n",
    "    temp_X_test, temp_y_test,\n",
    "    temp_X_combined, temp_y_combined,\n",
    "    temp_models_bayesian\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pressure Models using Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_results_hyperband"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pressure Models using Bayesian Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_results_bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature Models using Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_results_hyperband"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature Models using Bayesian Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_results_bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "This section finds the best models (lowest combined RMSE) based on the evaluation done previously, and visualises their accuracy using scatter plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pressure_model_hyperband = pressure_models_hyperband[pressure_results_hyperband['rmse_combined'].idxmin()]\n",
    "best_pressure_model_bayesian = pressure_models_bayesian[pressure_results_bayesian['rmse_combined'].idxmin()]\n",
    "best_temp_model_hyperband = temp_models_hyperband[temp_results_hyperband['rmse_combined'].idxmin()]\n",
    "best_temp_model_bayesian = temp_models_bayesian[temp_results_bayesian['rmse_combined'].idxmin()]\n",
    "\n",
    "# save models\n",
    "best_pressure_model_hyperband.save(f'pressure_model_hyperband.keras')\n",
    "best_pressure_model_bayesian.save(f'pressure_model_bayesian.keras')\n",
    "best_temp_model_hyperband.save(f'temp_model_hyperband.keras')\n",
    "best_temp_model_bayesian.save(f'temp_model_bayesian.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Pressure Model using Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model structure\n",
    "plot_model(best_pressure_model_hyperband, show_layer_names=False, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model optimiser\n",
    "best_pressure_model_hyperband.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Pressure Model using Bayesian Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model structure\n",
    "plot_model(best_pressure_model_bayesian, show_layer_names=False, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model optimiser\n",
    "best_pressure_model_bayesian.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Temperature Model using Hyperband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model structure\n",
    "plot_model(best_temp_model_hyperband, show_layer_names=False, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model optimiser\n",
    "best_temp_model_hyperband.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Temperature Model using Bayesian Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model structure\n",
    "plot_model(best_temp_model_bayesian, show_layer_names=False, show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model optimiser\n",
    "best_temp_model_bayesian.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Actual vs Prediction Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_vs_pred_plot(X_test, y_test, X_combined, y_combined, model, x_label, y_label, title):\n",
    "\tplt.rcParams.update({'font.size': 12}) # font size 16\n",
    "\n",
    "\t# make predictions\n",
    "\ty_pred_test = model.predict(X_test)\n",
    "\ty_pred_combined = model.predict(X_combined)\n",
    "\t\n",
    "\t# plot\n",
    "\t_, ax = plt.subplots(figsize=(5,5))\n",
    "\tideal_line_lim = max(max(y_combined), max(y_test))\n",
    "\tax.plot([0, ideal_line_lim], [0, ideal_line_lim], 'k', linewidth=1, label='Ideal', zorder=-1) # ideal line (i.e. x=y)\n",
    "\tax.scatter(y_combined, y_pred_combined, s=7, color=(0.00, 0.00, 0.55), label='Combined') # scatter plot for combined set\n",
    "\tax.scatter(y_test, y_pred_test, s=7, color=(0.91, 0.41, 0.17), label='Test') # scatter plot for test set\n",
    "\tax.set_title(title)\n",
    "\tax.set_xlabel(x_label)\n",
    "\tax.set_ylabel(y_label)\n",
    "\tplt.legend()\n",
    "\tplt.show()\n",
    "\n",
    "actual_vs_pred_plot(pressure_X_test, pressure_y_test, pressure_X_combined, pressure_y_combined, best_pressure_model_hyperband,\n",
    "\t\t\t\t\t'True ΔP / Pa', 'Predicted ΔP / Pa', 'Pressure Model (Hyperband)')\n",
    "actual_vs_pred_plot(pressure_X_test, pressure_y_test, pressure_X_combined, pressure_y_combined, best_pressure_model_bayesian,\n",
    "\t\t\t\t\t'True ΔP / Pa', 'Predicted ΔP / Pa', 'Pressure Model (Bayesian)')\n",
    "actual_vs_pred_plot(temp_X_test, temp_y_test, temp_X_combined, temp_y_combined, best_temp_model_hyperband,\n",
    "\t\t\t\t\t'True $T$ / $^\\circ\\mathrm{C}}$', 'Predicted $T$ / $^\\circ\\mathrm{C}}$', 'Temperature Model (Hyperband)')\n",
    "actual_vs_pred_plot(temp_X_test, temp_y_test, temp_X_combined, temp_y_combined, best_temp_model_bayesian,\n",
    "\t\t\t\t\t'True $T$ / $^\\circ\\mathrm{C}}$', 'Predicted $T$ / $^\\circ\\mathrm{C}}$', 'Temperature Model (Bayesian)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
